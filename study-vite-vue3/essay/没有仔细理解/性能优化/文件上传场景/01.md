给项目普通开发者的优化建议如果你现在是团队内的开发者之一，那你能做的，主要还是从开发者的角度去思考现在手里负责的需求如何能够更进一步做优化，首先是需求中的数据量比变大之后如何优化，我在这里给你举两个常见的场景，相信会带给你不少启发。文件上传的场景文件上传这个场景，是我很喜欢举的例子。像日常项目开发中的头像上传、用户简历上传、视频上传等等，都属于这类需求。我们直接使用 axios.post 就可以实现这个需求了，文件的体积就是这个场景下的数据量，那么文件变得很大之后，该如何处理呢？比如，在我们上传一个 2GB 大小的视频文件的时候，如果直接使用 axios.post 上传，那么中途一旦出现网络卡顿，就需要重新上传这个视频文件。这就会对用户的体验造成不好的影响，所以在这种数据量极大的场景下，我们需要采用断点续传的解决方案。对照下面断点续传的示意图，你能看到，我们可以把文件切成数据块依次上传，如果上传的过程中，出现了网络错误，那么再次上传的时候，就会把已经存在的切片列表过滤掉，只上传其他的切片。
图7
完成上述断点续传的功能之后，我们就完成了项目的初步优化，在文件上传之前，我们需要在前端计算出一个文件的 Hash 值作为唯一标识，用来向后端询问切片的列表。但是对于一个 2GB 大小的文件来说，即使是使用 MD5 算法来计算 Hash 值，也会造成浏览器的卡顿。那怎么解决计算 Hash 值时，浏览器的卡顿的问题呢？对于卡顿问题，我们可以通过 web-workder 去解决，这有点像孙悟空可以用猴毛变出一个分身，我们这里的 hash.js，就相当于浏览器主进程的分身，用分身就可以去计算 Hash 值，不耽误主进程的任务。在下面的代码中，我们使用 new Worker 加载一个 hash.js 去计算文件的 hash 值。

    async calculateHashWorker(chunks) {
      return new Promise(resolve => {
        // web-worker 防止卡顿主线程
        this.worker = new Worker("/hash.js")
        this.worker.postMessage({ chunks })
        this.worker.onmessage = e => {
          const { progress, hash } = e.data
          this.hashProgress = Number(progress.toFixed(2))
          if (hash) {
            resolve(hash)
          }
        };
      });
    },

    通过对性能瓶颈的分析，我们能看到，现在这个卡顿主要是由计算量过大导致的。在前端发展史那一讲中，我们有讲到：在 React 框架下，当项目庞大之后，如果 Diff 的计算量过大，那么也会导致卡顿。所以我们可以借鉴 React 的 Fiber 解决方案，使用浏览器的空闲时间去计算 Hash。在下面的代码中，我们使用 requestIdleCallback 启动空闲时间的计算任务，能很好地解决这个问题。

    
let count = 0
const workLoop = async deadline => {
  // 计算，并且当前帧还没结束
  while (count < chunks.length && deadline.timeRemaining() > 1) {
    await appendToSpark(chunks[count].file)
    count++
    // 没有了 计算完毕
    if (count < chunks.length) {
      // 计算中
      this.hashProgress = Number(
        ((100 * count) / chunks.length).toFixed(2)
      )
      // console.log(this.hashProgress)
    } else {
      // 计算完毕
      this.hashProgress = 100
      resolve(spark.end())
    }
  }
  window.requestIdleCallback(workLoop)
}
window.requestIdleCallback(workLoop)
这两段代码只是抛砖引玉，你还可以继续深挖这个需求，比如我们上传切片的时候，所有的文件切片一起使用 Promise.all 发起几十个 HTTP 请求，也会导致卡顿，所以我们就需要手动管理上传任务的并发数量。由于切片上传速度跟当前网速相关，所以在对上传任务的并发数量进行管理时，我们需要确定切片的大小。那该如何确定切片的大小呢？我们可以借鉴 TCP 协议的慢启动逻辑，去让切片的大小和当前网速匹配，这样，我们就可以通过网速确定切片的大小。当你顺着这个思路解决了大文件上传的需求之后，这就会成为你项目中的亮点。上述文件上传的演示代码，你可以点击这里的链接，去我的 GitHub 里直接获取。此外，还有一个典型的场景就是列表渲染，相信现在的你使用 v-for 就可以很快地实现这个需求。但是，你可以设想这样一个场景：列表的数据量不断增多，成千上万个数据的渲染让页面卡顿。按照我们优化需求的思路，需要你做的就是：使用虚拟列表来应对这个场景。